{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pandas_profiling as pp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 51)\n"
     ]
    }
   ],
   "source": [
    "# Read in CSV\n",
    "df = pd.read_csv(\"final_project.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename obvious columns\n",
    "df.rename(columns={'x24': 'continent', 'x29': 'month', 'x30': 'day'}, inplace = True)\n",
    "#list(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['europe' 'asia' 'america' 'other']\n",
      "['July' 'August' 'June' 'May' 'September' 'April' 'November' 'October'\n",
      " 'other' 'March' 'Feb' 'December' 'January']\n",
      "['tuesday' 'wednesday' 'thursday' 'monday' 'friday' 'other']\n"
     ]
    }
   ],
   "source": [
    "# Correct misspellings and standardize values in labeled columns\n",
    "df['continent'].replace('euorpe', 'europe',inplace=True)\n",
    "df['month'].replace('Dev', 'December',inplace=True)\n",
    "df['month'].replace('Aug', 'August',inplace=True)\n",
    "df['month'].replace('Jun', 'June',inplace=True)\n",
    "df['month'].replace('Apr', 'April',inplace=True)\n",
    "df['month'].replace('Nov', 'November',inplace=True)\n",
    "df['month'].replace('sept.', 'September',inplace=True)\n",
    "df['month'].replace('Oct', 'October',inplace=True)\n",
    "df['month'].replace('Mar', 'March',inplace=True)\n",
    "df['day'].replace('thurday', 'thursday',inplace=True)\n",
    "\n",
    "# Fill NA with 'other' in labeled columns\n",
    "df['continent'] = df['continent'].fillna('other')\n",
    "df['month'] = df['month'].fillna('other')\n",
    "df['day'] = df['day'].fillna('other')\n",
    "\n",
    "# check unique values in labeled columns\n",
    "print (df['continent'].unique())\n",
    "print (df['month'].unique())\n",
    "print (df['day'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['europe' 'asia' 'america' 'other']\n",
      "['7' '8' '6' '5' '9' '4' '11' '10' '0' '3' '2' '12' '1']\n",
      "['tuesday' 'wednesday' 'thursday' 'monday' 'friday' 'other']\n"
     ]
    }
   ],
   "source": [
    "# Correct misspellings and standardize values in labeled columns\n",
    "df['continent'].replace('euorpe', 'europe',inplace=True)\n",
    "df['month'].replace('Dev', '12',inplace=True)\n",
    "df['month'].replace('Aug', '8',inplace=True)\n",
    "df['month'].replace('Jun', '6',inplace=True)\n",
    "df['month'].replace('Apr', '4',inplace=True)\n",
    "df['month'].replace('Nov', '11',inplace=True)\n",
    "df['month'].replace('sept.', '9',inplace=True)\n",
    "df['month'].replace('Oct', '10',inplace=True)\n",
    "df['month'].replace('Mar', '3',inplace=True)\n",
    "df['month'].replace('January', '1',inplace=True)\n",
    "df['month'].replace('Feb', '2',inplace=True)\n",
    "df['month'].replace('May', '5',inplace=True)\n",
    "df['month'].replace('July', '7',inplace=True)\n",
    "df['month'].replace('December', '12',inplace=True)\n",
    "df['month'].replace('August', '8',inplace=True)\n",
    "df['month'].replace('June', '6',inplace=True)\n",
    "df['month'].replace('April', '4',inplace=True)\n",
    "df['month'].replace('November', '11',inplace=True)\n",
    "df['month'].replace('September', '9',inplace=True)\n",
    "df['month'].replace('October', '10',inplace=True)\n",
    "df['month'].replace('March', '3',inplace=True)\n",
    "df['day'].replace('thurday', 'thursday',inplace=True)\n",
    "\n",
    "\n",
    "# Fill NA with 'other' in labeled columns\n",
    "df['continent'] = df['continent'].fillna('other')\n",
    "df['month'] = df['month'].fillna('other')\n",
    "df['day'] = df['day'].fillna('other')\n",
    "df['month'].replace('other','0', inplace=True)\n",
    "\n",
    "# check unique values in labeled columns\n",
    "print (df['continent'].unique())\n",
    "print (df['month'].unique())\n",
    "print (df['day'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize temp for x37 column\n",
    "temp_x37 = []\n",
    "\n",
    "# Remove $ ) , characters and replace '(' with '-' \n",
    "for i in range (0,len(df)) :\n",
    "    try :\n",
    "        n = df['x37'][i]\n",
    "        nstr = re.sub(r'[$|,|)]',r'', n)\n",
    "        nstr = re.sub(r'[(]',r'-',nstr)\n",
    "        #nstr= float(nstr)\n",
    "        temp_x37.append(nstr)\n",
    "    except :\n",
    "        nstr = ''\n",
    "        temp_x37.append(nstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n",
      "160000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1313.96\n",
       "1         1962.78\n",
       "2          430.47\n",
       "3        -2366.29\n",
       "4         -620.66\n",
       "           ...   \n",
       "159995    -891.96\n",
       "159996    1588.65\n",
       "159997     687.46\n",
       "159998     439.21\n",
       "159999   -1229.34\n",
       "Name: x37, Length: 160000, dtype: float64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify len of both x37 matches\n",
    "print(len(df['x37']))\n",
    "print(len(temp_x37))\n",
    "\n",
    "# Replace 'x37' with new values and convert to numeric\n",
    "df['x37'] = temp_x37\n",
    "df[\"x37\"] = pd.to_numeric(df[\"x37\"])\n",
    "df['x37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia length is 138965\n",
      "america length is 4469\n",
      "europe length is 16538\n",
      "other length is 28\n"
     ]
    }
   ],
   "source": [
    "# Subsetting data set by continent and print length of each\n",
    "cont = ['asia', 'america','europe', 'other']\n",
    "\n",
    "for n in cont :\n",
    "    temp = df['continent'] == n\n",
    "    df_temp = df[temp]\n",
    "    #df_[n] = df_temp\n",
    "    print (n, 'length is', len(df_temp))\n",
    "\n",
    "# Subsetting by continent    \n",
    "is_asia = df['continent']=='asia'\n",
    "df_asia = df[is_asia]\n",
    "\n",
    "is_europe = df['continent']=='europe'\n",
    "df_europe = df[is_europe]\n",
    "\n",
    "is_america = df['continent']=='america'\n",
    "df_america = df[is_america]\n",
    "\n",
    "is_other = df['continent']=='other'\n",
    "df_other = df[is_other]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple and fast exploratory data analysis \n",
    "pp.ProfileReport(df_america)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with complete data set - Drop continent, x41, x6 per EDA suggestion.\n",
    "# Need to drop day, month, x32 since it's categorical\n",
    "lr_df = df.drop(['x41', 'x6', 'continent', 'day','x32'], axis=1)\n",
    "\n",
    "# Fill in NA with mean - LR needs values in each cell \n",
    "lr_df = lr_df.fillna(lr_df.mean())\n",
    "\n",
    "# Alternative - Drop all rows with NA\n",
    "lr_df_no = lr_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lr_df['y']\n",
    "X = lr_df.drop('y', axis = 1)\n",
    "\n",
    "# Model Fitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 70.27 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23697  4924]\n",
      " [ 9345 10034]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77     28621\n",
      "           1       0.67      0.52      0.58     19379\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     48000\n",
      "   macro avg       0.69      0.67      0.68     48000\n",
      "weighted avg       0.70      0.70      0.69     48000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Precision, recall, F-Measure and Support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp Dataset for Random Forest.  Dropped the highly correlated features.  Replace NaN with mean of column\n",
    "#rf_df = df.drop(['x41', 'x6'], axis=1)\n",
    "#rf_df = rf_df.fillna(lr_df.mean())\n",
    "\n",
    "rf_df = lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "#features = pd.get_dummies(rf_df)\n",
    "\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "#features.iloc[:,5:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8800625"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature of Importance\n",
    "# ref: https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\n",
    "\n",
    "y = lr_df['y']\n",
    "X = lr_df.drop('y', axis = 1)\n",
    "\n",
    "# Splitting data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "## Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "## Initiating Random Forest Classifier. \n",
    "rf = RandomForestClassifier() \n",
    "\n",
    "## Fitting model on training data.\n",
    "rf.fit(X_train, y_train) \n",
    "\n",
    "## Accuracy Score\n",
    "rf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       importance\n",
      "x23      0.080533\n",
      "x20      0.065573\n",
      "x48      0.059752\n",
      "x49      0.059402\n",
      "x38      0.054917\n",
      "x42      0.052851\n",
      "x12      0.051718\n",
      "x37      0.049289\n",
      "x27      0.048119\n",
      "x28      0.045811\n",
      "x7       0.043381\n",
      "x40      0.042580\n",
      "x46      0.041886\n",
      "x2       0.038460\n",
      "x18      0.009328\n",
      "x47      0.009145\n",
      "x31      0.009071\n",
      "x3       0.009013\n",
      "x5       0.008983\n",
      "x25      0.008943\n",
      "x11      0.008909\n",
      "x16      0.008867\n",
      "x45      0.008860\n",
      "x43      0.008860\n",
      "x26      0.008832\n",
      "x14      0.008819\n",
      "x39      0.008736\n",
      "x22      0.008732\n",
      "x13      0.008723\n",
      "x21      0.008699\n",
      "x8       0.008679\n",
      "x0       0.008610\n",
      "x36      0.008609\n",
      "x44      0.008600\n",
      "x33      0.008574\n",
      "x4       0.008551\n",
      "x19      0.008550\n",
      "x15      0.008536\n",
      "x10      0.008516\n",
      "x34      0.008469\n",
      "x35      0.008445\n",
      "x17      0.008441\n",
      "x1       0.008357\n",
      "x9       0.008327\n",
      "month    0.003945\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://towardsdatascience.com/decision-tree-in-python-b433ae57fb93\n",
    "#https://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO \n",
    "from IPython.display import Image \n",
    "from pydot import graph_from_dot_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  83.75416666666666 with Gini Index.\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred)*100, 'with Gini Index.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_ent = DecisionTreeClassifier(criterion='entropy',random_state=123)\n",
    "dt_ent.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  84.425 with Information Gain.\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt_ent.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred)*100, 'with Information Gain.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Logistic Regressions using Features of Importance\n",
    "Summary: Decision Tree yields the best accuracy at 86.85% using max_depth of 15 and entropy.  Logistic Regression showed tiny improvement from 70.27% to 70.33%.  Recommendation is to go with Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x23       x20       x48        x49        x38        x12       x42  \\\n",
      "0   3.553013 -1.909114  0.151589  -8.040166  -1.353729  25.665413  5.414063   \n",
      "1  10.590601 -5.809984 -0.320283  16.719974  32.816804 -25.014934  4.490915   \n",
      "2  -5.270615  1.700321 -2.090804  -7.869421  -0.333199  12.078602  9.088864   \n",
      "3 -11.484431  1.923670  1.806070  -7.670847  14.188669  10.995330 -7.467775   \n",
      "4 -15.998166 -9.026317 -0.894942  15.724742 -12.578926 -28.106348 -5.229937   \n",
      "\n",
      "        x27        x40      x37        x28         x7         x2        x46  y  \n",
      "0  1.005131 -10.612200  1313.96 -18.473784 -14.789997   4.621113  60.781427  0  \n",
      "1  0.751086   2.147427  1962.78   3.749377  -6.725709  27.839856  15.805696  0  \n",
      "2  4.171088  -0.863137   430.47  11.522448  11.060572  12.251561  30.856417  0  \n",
      "3  9.215569  12.084421 -2366.29  30.595226 -18.913592 -24.149632 -72.424569  0  \n",
      "4  1.811182  30.004727  -620.66  -4.094084  27.532281 -11.352593 -14.085435  1  \n",
      "(160000, 15)\n"
     ]
    }
   ],
   "source": [
    "# Subsetting by feature of importance from RF\n",
    "#rf_df_1 = lr_df [['x23', 'x12', 'x20', 'x48', 'x49', 'x27', 'x28','x37', 'x38', 'x42', 'x2', 'x7' ,'x46', 'x40', 'y']]\n",
    "\n",
    "# importance > .04\n",
    "rf_df_1 = lr_df [['x23', 'x20', 'x48', 'x49', 'x38', 'x12', 'x42', 'x27','x40', 'x37','x28','x7','x2', 'x46', 'y']]\n",
    "\n",
    "#rf_df_1 = lr_df [['x23', 'x20', 'x48', 'x49', 'x38', 'y']] - this set yielded a worse accuracy. importance > 0.05\n",
    "print(rf_df_1.head())\n",
    "print(rf_df_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree w/ Feature of Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_1 = rf_df_1['y']\n",
    "#X_1 = rf_df_1.drop('y', axis = 1)\n",
    "\n",
    "#rf_df_sample = rf_df.sample(frac=.95)\n",
    "\n",
    "y_1 = rf_df_1['y']\n",
    "X_1 = rf_df_1.drop('y', axis = 1)\n",
    "\n",
    "# Model Fitting\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1, y_1, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  85.87708333333333 with Gini Index.\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "dt.fit(X_train1, y_train1)\n",
    "y_pred1 = dt.predict(X_test1)\n",
    "print (\"Accuracy is \", accuracy_score(y_test1,y_pred1)*100, 'with Gini Index.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  86.03541666666666 with Information Gain.\n"
     ]
    }
   ],
   "source": [
    "dt_ent = DecisionTreeClassifier(criterion='entropy',random_state=123)\n",
    "dt_ent.fit(X_train1, y_train1)\n",
    "y_pred1 = dt_ent.predict(X_test1)\n",
    "print (\"Accuracy is \", accuracy_score(y_test1,y_pred1)*100, 'with Information Gain.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  76.93541666666667 with Gini Index at 5 depth\n",
      "Accuracy is  84.64791666666667 with Gini Index at 10 depth\n",
      "Accuracy is  85.25416666666666 with Gini Index at 11 depth\n",
      "Accuracy is  86.15416666666667 with Gini Index at 12 depth\n",
      "Accuracy is  86.34791666666666 with Gini Index at 13 depth\n",
      "Accuracy is  86.65625 with Gini Index at 14 depth\n",
      "Accuracy is  86.85208333333333 with Gini Index at 15 depth\n",
      "Accuracy is  86.55000000000001 with Gini Index at 16 depth\n",
      "Accuracy is  86.69583333333334 with Gini Index at 17 depth\n",
      "Accuracy is  86.63125000000001 with Gini Index at 18 depth\n",
      "Accuracy is  86.47083333333333 with Gini Index at 19 depth\n",
      "Accuracy is  86.41041666666666 with Gini Index at 20 depth\n",
      "Accuracy is  86.21041666666667 with Gini Index at 22 depth\n",
      "Accuracy is  85.95208333333333 with Gini Index at 25 depth\n",
      "Accuracy is  85.87708333333333 with Gini Index at 50 depth\n",
      "Accuracy is  85.87708333333333 with Gini Index at 100 depth\n"
     ]
    }
   ],
   "source": [
    "n_est = [5, 10, 11,12,13,14,15, 16, 17,18,19, 20, 22, 25, 50, 100]\n",
    "for n in n_est :\n",
    "    dt = DecisionTreeClassifier(random_state=123, max_depth = n)\n",
    "    dt.fit(X_train1, y_train1)\n",
    "    y_pred1 = dt.predict(X_test1)\n",
    "    print (\"Accuracy is \", accuracy_score(y_test1,y_pred1)*100, 'with Gini Index at', n, 'depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  76.02499999999999 with Information Gain at 5 depth\n",
      "Accuracy is  83.61041666666667 with Information Gain at 10 depth\n",
      "Accuracy is  84.32916666666667 with Information Gain at 11 depth\n",
      "Accuracy is  85.00208333333333 with Information Gain at 12 depth\n",
      "Accuracy is  85.55416666666666 with Information Gain at 13 depth\n",
      "Accuracy is  85.77291666666666 with Information Gain at 14 depth\n",
      "Accuracy is  86.38958333333333 with Information Gain at 15 depth\n",
      "Accuracy is  86.33541666666666 with Information Gain at 16 depth\n",
      "Accuracy is  86.3 with Information Gain at 17 depth\n",
      "Accuracy is  86.22916666666667 with Information Gain at 18 depth\n",
      "Accuracy is  86.25625 with Information Gain at 19 depth\n",
      "Accuracy is  86.12291666666667 with Information Gain at 20 depth\n",
      "Accuracy is  86.17291666666667 with Information Gain at 22 depth\n",
      "Accuracy is  85.99166666666666 with Information Gain at 25 depth\n",
      "Accuracy is  86.03541666666666 with Information Gain at 50 depth\n",
      "Accuracy is  86.03541666666666 with Information Gain at 100 depth\n"
     ]
    }
   ],
   "source": [
    "n_est = [5, 10, 11,12,13,14,15, 16, 17,18,19, 20, 22, 25, 50, 100]\n",
    "for n in n_est :\n",
    "    dt = DecisionTreeClassifier(criterion = 'entropy',random_state=123, max_depth = n)\n",
    "    dt.fit(X_train1, y_train1)\n",
    "    y_pred1 = dt.predict(X_test1)\n",
    "    print (\"Accuracy is \", accuracy_score(y_test1,y_pred1)*100, 'with Information Gain at', n, 'depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ Feature of Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=123)\n",
    "logreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 70.33 %\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = logreg.predict(X_test1)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test1, y_test1)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23838  4998]\n",
      " [ 9243  9921]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test1, y_pred1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77     28836\n",
      "           1       0.66      0.52      0.58     19164\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     48000\n",
      "   macro avg       0.69      0.67      0.68     48000\n",
      "weighted avg       0.70      0.70      0.70     48000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Precision, recall, F-Measure and Support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test1, y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
